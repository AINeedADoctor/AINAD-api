{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dc7cd7b3-32e0-4284-b669-87d4fb6dbaf8",
    "_uuid": "dfeb8a6c8cc31996e69537a9a25102c42ccf3e6d"
   },
   "source": [
    "<a id='Library_and_data_loading'></a>\n",
    "## **1. Library and data loading** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "507667c6-d01e-44e4-b8d7-a2d61d3eb02a",
    "_uuid": "d59a9a91a5da35354233aaf9fc1f0dd66686349b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1259, 27)\n",
      "                Age\n",
      "count  1.259000e+03\n",
      "mean   7.942815e+07\n",
      "std    2.818299e+09\n",
      "min   -1.726000e+03\n",
      "25%    2.700000e+01\n",
      "50%    3.100000e+01\n",
      "75%    3.600000e+01\n",
      "max    1.000000e+11\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1259 entries, 0 to 1258\n",
      "Data columns (total 27 columns):\n",
      "Timestamp                    1259 non-null object\n",
      "Age                          1259 non-null int64\n",
      "Gender                       1259 non-null object\n",
      "Country                      1259 non-null object\n",
      "state                        744 non-null object\n",
      "self_employed                1241 non-null object\n",
      "family_history               1259 non-null object\n",
      "treatment                    1259 non-null object\n",
      "work_interfere               995 non-null object\n",
      "no_employees                 1259 non-null object\n",
      "remote_work                  1259 non-null object\n",
      "tech_company                 1259 non-null object\n",
      "benefits                     1259 non-null object\n",
      "care_options                 1259 non-null object\n",
      "wellness_program             1259 non-null object\n",
      "seek_help                    1259 non-null object\n",
      "anonymity                    1259 non-null object\n",
      "leave                        1259 non-null object\n",
      "mental_health_consequence    1259 non-null object\n",
      "phys_health_consequence      1259 non-null object\n",
      "coworkers                    1259 non-null object\n",
      "supervisor                   1259 non-null object\n",
      "mental_health_interview      1259 non-null object\n",
      "phys_health_interview        1259 non-null object\n",
      "mental_vs_physical           1259 non-null object\n",
      "obs_consequence              1259 non-null object\n",
      "comments                     164 non-null object\n",
      "dtypes: int64(1), object(26)\n",
      "memory usage: 265.6+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Country</th>\n",
       "      <th>state</th>\n",
       "      <th>self_employed</th>\n",
       "      <th>family_history</th>\n",
       "      <th>treatment</th>\n",
       "      <th>work_interfere</th>\n",
       "      <th>no_employees</th>\n",
       "      <th>...</th>\n",
       "      <th>leave</th>\n",
       "      <th>mental_health_consequence</th>\n",
       "      <th>phys_health_consequence</th>\n",
       "      <th>coworkers</th>\n",
       "      <th>supervisor</th>\n",
       "      <th>mental_health_interview</th>\n",
       "      <th>phys_health_interview</th>\n",
       "      <th>mental_vs_physical</th>\n",
       "      <th>obs_consequence</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-08-27 11:29:31</td>\n",
       "      <td>37</td>\n",
       "      <td>Female</td>\n",
       "      <td>United States</td>\n",
       "      <td>IL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Often</td>\n",
       "      <td>6-25</td>\n",
       "      <td>...</td>\n",
       "      <td>Somewhat easy</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Some of them</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Maybe</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-08-27 11:29:37</td>\n",
       "      <td>44</td>\n",
       "      <td>M</td>\n",
       "      <td>United States</td>\n",
       "      <td>IN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Rarely</td>\n",
       "      <td>More than 1000</td>\n",
       "      <td>...</td>\n",
       "      <td>Don't know</td>\n",
       "      <td>Maybe</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Don't know</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-08-27 11:29:44</td>\n",
       "      <td>32</td>\n",
       "      <td>Male</td>\n",
       "      <td>Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Rarely</td>\n",
       "      <td>6-25</td>\n",
       "      <td>...</td>\n",
       "      <td>Somewhat difficult</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-08-27 11:29:46</td>\n",
       "      <td>31</td>\n",
       "      <td>Male</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Often</td>\n",
       "      <td>26-100</td>\n",
       "      <td>...</td>\n",
       "      <td>Somewhat difficult</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Some of them</td>\n",
       "      <td>No</td>\n",
       "      <td>Maybe</td>\n",
       "      <td>Maybe</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-27 11:30:22</td>\n",
       "      <td>31</td>\n",
       "      <td>Male</td>\n",
       "      <td>United States</td>\n",
       "      <td>TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Never</td>\n",
       "      <td>100-500</td>\n",
       "      <td>...</td>\n",
       "      <td>Don't know</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Some of them</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Don't know</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Timestamp  Age  Gender         Country state self_employed  \\\n",
       "0  2014-08-27 11:29:31   37  Female   United States    IL           NaN   \n",
       "1  2014-08-27 11:29:37   44       M   United States    IN           NaN   \n",
       "2  2014-08-27 11:29:44   32    Male          Canada   NaN           NaN   \n",
       "3  2014-08-27 11:29:46   31    Male  United Kingdom   NaN           NaN   \n",
       "4  2014-08-27 11:30:22   31    Male   United States    TX           NaN   \n",
       "\n",
       "  family_history treatment work_interfere    no_employees   ...     \\\n",
       "0             No       Yes          Often            6-25   ...      \n",
       "1             No        No         Rarely  More than 1000   ...      \n",
       "2             No        No         Rarely            6-25   ...      \n",
       "3            Yes       Yes          Often          26-100   ...      \n",
       "4             No        No          Never         100-500   ...      \n",
       "\n",
       "                leave mental_health_consequence phys_health_consequence  \\\n",
       "0       Somewhat easy                        No                      No   \n",
       "1          Don't know                     Maybe                      No   \n",
       "2  Somewhat difficult                        No                      No   \n",
       "3  Somewhat difficult                       Yes                     Yes   \n",
       "4          Don't know                        No                      No   \n",
       "\n",
       "      coworkers supervisor mental_health_interview phys_health_interview  \\\n",
       "0  Some of them        Yes                      No                 Maybe   \n",
       "1            No         No                      No                    No   \n",
       "2           Yes        Yes                     Yes                   Yes   \n",
       "3  Some of them         No                   Maybe                 Maybe   \n",
       "4  Some of them        Yes                     Yes                   Yes   \n",
       "\n",
       "  mental_vs_physical obs_consequence comments  \n",
       "0                Yes              No      NaN  \n",
       "1         Don't know              No      NaN  \n",
       "2                 No              No      NaN  \n",
       "3                 No             Yes      NaN  \n",
       "4         Don't know              No      NaN  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import randint\n",
    "import seaborn as sns\n",
    "\n",
    "# prep\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import binarize, LabelEncoder, MinMaxScaler\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "# Validation libraries\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, precision_recall_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "#Bagging\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "\n",
    "#Naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "#reading in CSV's from a file path\n",
    "train_df = pd.read_csv('datasets/survey.csv')\n",
    "\n",
    "\n",
    "#Pandas: whats the data row count?\n",
    "print(train_df.shape)\n",
    "    \n",
    "#Pandas: whats the distribution of the data?\n",
    "print(train_df.describe())\n",
    "    \n",
    "#Pandas: What types of data do i have?\n",
    "print(train_df.info())\n",
    "\n",
    "train_df = train_df.append(train_df)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-83ec5aec282a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtreatment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hackupc/AINAD-api/venv/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, normed, data, **kwargs)\u001b[0m\n\u001b[1;32m   2617\u001b[0m         \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2618\u001b[0m         \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2619\u001b[0;31m         data=data, **kwargs)\n\u001b[0m\u001b[1;32m   2620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2621\u001b[0m \u001b[0;31m# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hackupc/AINAD-api/venv/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1783\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1784\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1785\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1787\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/hackupc/AINAD-api/venv/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(self, x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, normed, **kwargs)\u001b[0m\n\u001b[1;32m   6643\u001b[0m                 patch = _barfunc(bins[:-1]+boffset, height, width,\n\u001b[1;32m   6644\u001b[0m                                  \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6645\u001b[0;31m                                  color=c, **{bottom_kwarg: bottom})\n\u001b[0m\u001b[1;32m   6646\u001b[0m                 \u001b[0mpatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6647\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstacked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hackupc/AINAD-api/venv/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1783\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1784\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1785\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1787\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/hackupc/AINAD-api/venv/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2332\u001b[0m             \u001b[0mymin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mymin\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2333\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintervaly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mymin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2334\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoscale_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2336\u001b[0m         \u001b[0mbar_container\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBarContainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrorbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hackupc/AINAD-api/venv/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mautoscale_view\u001b[0;34m(self, tight, scalex, scaley)\u001b[0m\n\u001b[1;32m   2402\u001b[0m             \u001b[0mstickies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msticky_edges\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0martist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2403\u001b[0m             \u001b[0mx_stickies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msticky\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msticky\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstickies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2404\u001b[0;31m             \u001b[0my_stickies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msticky\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msticky\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstickies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2405\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'log'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2406\u001b[0m                 \u001b[0mx_stickies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_stickies\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mxs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9a8c2272-ba6c-477a-9710-b82d57a1804f",
    "_uuid": "e4eef2cb6628af4e719fdbd434ccbacc1846e487"
   },
   "source": [
    "<a id='Data_cleaning'></a>\n",
    "## **2. Data cleaning** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a8e060e1-18fa-4214-a6fb-f924f74af108",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "6088e9b05d062fbed2c2272924e9d8aa0e23e5b7",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#missing data\n",
    "total = train_df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (train_df.isnull().sum()/train_df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(20)\n",
    "print(missing_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d21825da-92d6-48e2-9ab9-c63fbbbbd2b7",
    "_uuid": "50bdd9973655b16c61711d519645df6afb2ca214"
   },
   "outputs": [],
   "source": [
    "#dealing with missing data\n",
    "#Let’s get rid of the variables \"Timestamp\",“comments”, “state” just to make our lives easier.\n",
    "train_df = train_df.drop(['comments'], axis= 1)\n",
    "train_df = train_df.drop(['state'], axis= 1)\n",
    "train_df = train_df.drop(['Timestamp'], axis= 1)\n",
    "\n",
    "train_df.isnull().sum().max() #just checking that there's no missing data missing...\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "871f195e-d25d-426a-84f5-997b017b892c",
    "_uuid": "7a54d86c30dab2e270e7374455178f8abcc15a7c"
   },
   "source": [
    "**Cleaning NaN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2bf70e26-afd9-4766-95ae-68d8ff9b21db",
    "_uuid": "08b863f7d666b7e68cef056ba2a0ae033cbdeb9d"
   },
   "outputs": [],
   "source": [
    "# Assign default values for each data type\n",
    "defaultInt = 0\n",
    "defaultString = 'NaN'\n",
    "defaultFloat = 0.0\n",
    "\n",
    "# Create lists by data tpe\n",
    "intFeatures = ['Age']\n",
    "stringFeatures = ['Gender', 'Country', 'self_employed', 'family_history', 'treatment', 'work_interfere',\n",
    "                 'no_employees', 'remote_work', 'tech_company', 'anonymity', 'leave', 'mental_health_consequence',\n",
    "                 'phys_health_consequence', 'coworkers', 'supervisor', 'mental_health_interview', 'phys_health_interview',\n",
    "                 'mental_vs_physical', 'obs_consequence', 'benefits', 'care_options', 'wellness_program',\n",
    "                 'seek_help']\n",
    "floatFeatures = []\n",
    "\n",
    "# Clean the NaN's\n",
    "for feature in train_df:\n",
    "    if feature in intFeatures:\n",
    "        train_df[feature] = train_df[feature].fillna(defaultInt)\n",
    "    elif feature in stringFeatures:\n",
    "        train_df[feature] = train_df[feature].fillna(defaultString)\n",
    "    elif feature in floatFeatures:\n",
    "        train_df[feature] = train_df[feature].fillna(defaultFloat)\n",
    "    else:\n",
    "        print('Error: Feature %s not recognized.' % feature)\n",
    "train_df.head(5)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4ec04bf5-c88f-4839-a79b-2d3ad6962599",
    "_uuid": "4507b7c43c9663f90a9cf915dd73850e4e0f17ab"
   },
   "outputs": [],
   "source": [
    "#clean 'Gender'\n",
    "#Slower case all columm's elements\n",
    "gender = train_df['Gender'].str.lower()\n",
    "#print(gender)\n",
    "\n",
    "#Select unique elements\n",
    "gender = train_df['Gender'].unique()\n",
    "\n",
    "#Made gender groups\n",
    "male_str = [\"male\", \"m\", \"male-ish\", \"maile\", \"mal\", \"male (cis)\", \"make\", \"male \", \"man\",\"msle\", \"mail\", \"malr\",\"cis man\", \"Cis Male\", \"cis male\"]\n",
    "trans_str = [\"trans-female\", \"something kinda male?\", \"queer/she/they\", \"non-binary\",\"nah\", \"all\", \"enby\", \"fluid\", \"genderqueer\", \"androgyne\", \"agender\", \"male leaning androgynous\", \"guy (-ish) ^_^\", \"trans woman\", \"neuter\", \"female (trans)\", \"queer\", \"ostensibly male, unsure what that really means\"]           \n",
    "female_str = [\"cis female\", \"f\", \"female\", \"woman\",  \"femake\", \"female \",\"cis-female/femme\", \"female (cis)\", \"femail\"]\n",
    "\n",
    "for (row, col) in train_df.iterrows():\n",
    "\n",
    "    if str.lower(col.Gender) in male_str:\n",
    "        train_df['Gender'].replace(to_replace=col.Gender, value='male', inplace=True)\n",
    "\n",
    "    if str.lower(col.Gender) in female_str:\n",
    "        train_df['Gender'].replace(to_replace=col.Gender, value='female', inplace=True)\n",
    "\n",
    "    if str.lower(col.Gender) in trans_str:\n",
    "        train_df['Gender'].replace(to_replace=col.Gender, value='trans', inplace=True)\n",
    "\n",
    "#Get rid of bullshit\n",
    "stk_list = ['A little about you', 'p']\n",
    "train_df = train_df[~train_df['Gender'].isin(stk_list)]\n",
    "\n",
    "print(train_df['Gender'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0e211fa8-a69e-42c1-adda-375d82916db4",
    "_uuid": "818c6a88caf07379d5012f15919d6eb46ae6d98c"
   },
   "outputs": [],
   "source": [
    "#complete missing age with mean\n",
    "train_df['Age'].fillna(train_df['Age'].median(), inplace = True)\n",
    "\n",
    "# Fill with media() values < 18 and > 120\n",
    "s = pd.Series(train_df['Age'])\n",
    "s[s<18] = train_df['Age'].median()\n",
    "train_df['Age'] = s\n",
    "s = pd.Series(train_df['Age'])\n",
    "s[s>120] = train_df['Age'].median()\n",
    "train_df['Age'] = s\n",
    "\n",
    "#Ranges of Age\n",
    "train_df['age_range'] = pd.cut(train_df['Age'], [0,20,30,65,100], labels=[\"0-20\", \"21-30\", \"31-65\", \"66-100\"], include_lowest=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ffa02f53-30cd-4f7e-bcd9-f74b3c0826c4",
    "_uuid": "55b6621c02ca8d8603d815da74b15ad621b46629"
   },
   "outputs": [],
   "source": [
    "#There are only 0.014% of self employed so let's change NaN to NOT self_employed\n",
    "#Replace \"NaN\" string from defaultString\n",
    "train_df['self_employed'] = train_df['self_employed'].replace([defaultString], 'No')\n",
    "print(train_df['self_employed'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d910581d-4b92-4919-ab5a-85b018158745",
    "_uuid": "b934d97a22a46c36e107d2e0fdeb9f0ee74dc532"
   },
   "outputs": [],
   "source": [
    "#There are only 0.20% of self work_interfere so let's change NaN to \"Don't know\n",
    "#Replace \"NaN\" string from defaultString\n",
    "\n",
    "train_df['work_interfere'] = train_df['work_interfere'].replace([defaultString], 'Don\\'t know' )\n",
    "print(train_df['work_interfere'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b77019bf-b900-4c2b-9676-792860d89825",
    "_uuid": "01bdb3e74278bd61fdbdda9b1f9a3085c873999b"
   },
   "source": [
    "<a id='Encoding_data'></a>\n",
    "## **3. Encoding data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "05a6455e-187d-4db2-bb71-4fbf2ba6d967",
    "_uuid": "af23578fce1520cbe5fd970b13c7ddd71f442018"
   },
   "outputs": [],
   "source": [
    "#Encoding data\n",
    "labelDict = {}\n",
    "for feature in train_df:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(train_df[feature])\n",
    "    joblib.dump(le, \"encoders/label_\" + feature + \".sav\")\n",
    "    le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    train_df[feature] = le.transform(train_df[feature])\n",
    "    # Get labels\n",
    "    labelKey = 'label_' + feature\n",
    "    labelValue = [*le_name_mapping]\n",
    "    labelDict[labelKey] =labelValue\n",
    "    \n",
    "\n",
    "for key, value in labelDict.items():     \n",
    "    print(key, value)\n",
    "\n",
    "#Get rid of 'Country'\n",
    "# train_df = train_df.drop(['Country'], axis= 1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "38b322d1-4aa6-468d-b370-cc93d43272c2",
    "_uuid": "f1cc9baff7c37cdad9014bccd875f0328b9c0d9b"
   },
   "source": [
    "### Testing there aren't any missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0031aa27-9d12-4cae-b59a-9897371789c0",
    "_uuid": "0958b0da3e0f1e2aa54914da431f47a773b8dec0"
   },
   "outputs": [],
   "source": [
    "#missing data\n",
    "total = train_df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (train_df.isnull().sum()/train_df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(20)\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "245bfde3-4bf8-4f4f-8cc6-9e1d95b632a7",
    "_uuid": "d9c414ad9ba5ed0ceb519beb410bccd8c12a117e"
   },
   "source": [
    "Features Scaling\n",
    "We're going to scale age, because is extremely different from the othere ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b56ba09c-796d-4515-95fc-b36611cdb266",
    "_uuid": "75911eb1235de12aa6277ec8751d336f60ba9eb8"
   },
   "source": [
    "<a id='Covariance_Matrix'></a>\n",
    "## **4. Covariance Matrix. Variability comparison between categories of variables** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fa764109-e028-4ca6-a167-281f8dcf1056",
    "_uuid": "db911626ce6498bac062d8dc7e01bfe670427fb4"
   },
   "outputs": [],
   "source": [
    "#correlation matrix\n",
    "corrmat = train_df.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);\n",
    "plt.show()\n",
    "\n",
    "#treatment correlation matrix\n",
    "k = 10 #number of variables for heatmap\n",
    "cols = corrmat.nlargest(k, 'treatment')['treatment'].index\n",
    "cm = np.corrcoef(train_df[cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f71d0c3d-8554-4478-b1d5-7aa461fcb7bb",
    "_uuid": "22adfaf19848e1103804bf8737cb5656fcac5388"
   },
   "source": [
    "<a id='Some_charts_to_see_data_relationship'></a>\n",
    "## **5. Some charts to see data relationship** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2af9fb8b-79ac-4444-95b0-210c704afef9",
    "_uuid": "39488f9878f2ab937c4ce888eb82eba133fb175c"
   },
   "source": [
    "Distribiution and density by Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "89387b66-3a36-4b3f-98a4-254253452056",
    "_uuid": "e7288897925d3f340ba4c2e73d2ef61c6ca28c4f"
   },
   "outputs": [],
   "source": [
    "# Distribiution and density by Age\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.distplot(train_df[\"Age\"], bins=24)\n",
    "plt.title(\"Distribuition and density by Age\")\n",
    "plt.xlabel(\"Age\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a8880fbd-1545-48dd-a850-1ccc6214bcdc",
    "_uuid": "9c24e2674ba7fe8cfecc0b911e6773512b7099c5"
   },
   "source": [
    "Separate by treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b464a345-00b2-47a2-9d3e-c7074cfaf790",
    "_uuid": "2cc9d4abe3ca092a5bf9b7a9cd9f0b4d443c0471"
   },
   "outputs": [],
   "source": [
    "# Separate by treatment or not\n",
    "\n",
    "g = sns.FacetGrid(train_df, col='treatment', size=5)\n",
    "g = g.map(sns.distplot, \"Age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "20b446a7-fe87-478d-9328-de7ea7afea5b",
    "_uuid": "1bfd6affb0501138a98d4dbc9c70ad491b35962c"
   },
   "source": [
    "How many people has been treated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "81f1eb2a-c3ac-433d-a674-24aa6a33d287",
    "_uuid": "ac35d322a601a3ff9fdde64fa5e33b28dbdd10e5"
   },
   "outputs": [],
   "source": [
    "# Let see how many people has been treated\n",
    "plt.figure(figsize=(12,8))\n",
    "labels = labelDict['label_Gender']\n",
    "g = sns.countplot(x=\"treatment\", data=train_df)\n",
    "g.set_xticklabels(labels)\n",
    "\n",
    "plt.title('Total Distribuition by treated or not')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d7a9a45c-0df3-48a4-9ab2-e5aaae9abe7f",
    "_uuid": "a781bf88a14f5bb937ede09d81365f16bdcbbe3f"
   },
   "source": [
    "Draw a nested barplot to show probabilities for class and sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "210c02cf-9296-4373-8725-bd13b819a9e4",
    "_uuid": "2b931335e19a15bf897fa8a6eabcd26cb263503a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "o = labelDict['label_age_range']\n",
    "\n",
    "g = sns.factorplot(x=\"age_range\", y=\"treatment\", hue=\"Gender\", data=train_df, kind=\"bar\",  ci=None, size=5, aspect=2, legend_out = True)\n",
    "g.set_xticklabels(o)\n",
    "\n",
    "plt.title('Probability of mental health condition')\n",
    "plt.ylabel('Probability x 100')\n",
    "plt.xlabel('Age')\n",
    "# replace legend labels\n",
    "\n",
    "new_labels = labelDict['label_Gender']\n",
    "for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
    "\n",
    "# Positioning the legend\n",
    "g.fig.subplots_adjust(top=0.9,right=0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6517af95-3b02-4b50-b246-ea56f61f6113",
    "_uuid": "4ed2e62093d643cf105829ff2ae9a9917b110996"
   },
   "source": [
    "Barplot to show probabilities for family history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b93d6150-b23a-4b71-8cf8-a10b811152a8",
    "_uuid": "605bf86a497f0b7989b57a3458088131f564e2a8"
   },
   "outputs": [],
   "source": [
    "o = labelDict['label_family_history']\n",
    "g = sns.factorplot(x=\"family_history\", y=\"treatment\", hue=\"Gender\", data=train_df, kind=\"bar\", ci=None, size=5, aspect=2, legend_out = True)\n",
    "g.set_xticklabels(o)\n",
    "plt.title('Probability of mental health condition')\n",
    "plt.ylabel('Probability x 100')\n",
    "plt.xlabel('Family History')\n",
    "\n",
    "# replace legend labels\n",
    "new_labels = labelDict['label_Gender']\n",
    "for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
    "\n",
    "# Positioning the legend\n",
    "g.fig.subplots_adjust(top=0.9,right=0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "beecc2fe-4cd8-489c-bc0e-bb5ad633931c",
    "_uuid": "7c7baa6c000ab81edb071071d45bac309f796d80"
   },
   "source": [
    "Barplot to show probabilities for care options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c77da62e-f71f-49fb-9c13-fe2fea3d474e",
    "_uuid": "bc61dc5b0c4c0a8204453524438006a84f6168d1"
   },
   "outputs": [],
   "source": [
    "o = labelDict['label_care_options']\n",
    "g = sns.factorplot(x=\"care_options\", y=\"treatment\", hue=\"Gender\", data=train_df, kind=\"bar\", ci=None, size=5, aspect=2, legend_out = True)\n",
    "g.set_xticklabels(o)\n",
    "plt.title('Probability of mental health condition')\n",
    "plt.ylabel('Probability x 100')\n",
    "plt.xlabel('Care options')\n",
    "\n",
    "# replace legend labels\n",
    "new_labels = labelDict['label_Gender']\n",
    "for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
    "\n",
    "# Positioning the legend\n",
    "g.fig.subplots_adjust(top=0.9,right=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "56de0fc1-8ee1-41b8-868e-133db7635c64",
    "_uuid": "5f9e29712de3b44df01755c481b898a38e508f07"
   },
   "source": [
    "Barplot to show probabilities for benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4fab65ea-f3f5-4831-9f3f-7560fb908d3e",
    "_uuid": "25c2da49fd8c83fc2d42355c0e147f439c00a7c0"
   },
   "outputs": [],
   "source": [
    "o = labelDict['label_benefits']\n",
    "g = sns.factorplot(x=\"care_options\", y=\"treatment\", hue=\"Gender\", data=train_df, kind=\"bar\", ci=None, size=5, aspect=2, legend_out = True)\n",
    "g.set_xticklabels(o)\n",
    "plt.title('Probability of mental health condition')\n",
    "plt.ylabel('Probability x 100')\n",
    "plt.xlabel('Benefits')\n",
    "\n",
    "# replace legend labels\n",
    "new_labels = labelDict['label_Gender']\n",
    "for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
    "\n",
    "# Positioning the legend\n",
    "g.fig.subplots_adjust(top=0.9,right=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bebe13ce-94d5-487c-88b8-7a634f361223",
    "_uuid": "9cfc643a94d39e2c06ed870c306deee6a9219b60"
   },
   "source": [
    "Barplot to show probabilities for work interfere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1606646f-0db7-41f9-b4bc-f8f2c982087c",
    "_uuid": "a7f3daeded334645d4cf5bd202e3116811159481"
   },
   "outputs": [],
   "source": [
    "o = labelDict['label_work_interfere']\n",
    "g = sns.factorplot(x=\"work_interfere\", y=\"treatment\", hue=\"Gender\", data=train_df, kind=\"bar\", ci=None, size=5, aspect=2, legend_out = True)\n",
    "g.set_xticklabels(o)\n",
    "plt.title('Probability of mental health condition')\n",
    "plt.ylabel('Probability x 100')\n",
    "plt.xlabel('Work interfere')\n",
    "\n",
    "# replace legend labels\n",
    "new_labels = labelDict['label_Gender']\n",
    "for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
    "\n",
    "# Positioning the legend\n",
    "g.fig.subplots_adjust(top=0.9,right=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4ea1fe2d-e6bd-434f-807c-9936f17be784",
    "_uuid": "ebb8c1dc1fdd5dcfa5f9d1b05db3d23323b21adc"
   },
   "source": [
    "<a id='Scaling_and_fitting'></a>\n",
    "## **6. Scaling and fitting** ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3687ae06-561c-4a0c-94a4-aad2275022ce",
    "_uuid": "6477bae9fc3654aef51e7048c0382c7888c9e36c"
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "feature_cols = ['Age', 'Gender', 'family_history', 'self_employed', 'remote_work', 'tech_company', 'no_employees', 'work_interfere']\n",
    "X = train_df[feature_cols]\n",
    "y = train_df.treatment\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Create dictionaries for final graph\n",
    "# Use: methodDict['Stacking'] = accuracy_score\n",
    "methodDict = {}\n",
    "rmseDict = ()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b958ffcc-6625-421e-b5d0-57cdd753d32f",
    "_uuid": "5cbfa3c0808b550849fbe80158556775a4367b03"
   },
   "outputs": [],
   "source": [
    "# Build a forest and compute the feature importances\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "\n",
    "forest.fit(X, y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "labels = []\n",
    "for f in range(X.shape[1]):\n",
    "    labels.append(feature_cols[f])      \n",
    "    \n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), labels, rotation='vertical')\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b07c9bf0-3323-4cb3-9589-fe64b1fd854a",
    "_uuid": "a5a4b72ee4b193749ff0f59acb689c5900d98ec1"
   },
   "source": [
    "<a id='Tuning'></a>\n",
    "## **7. Tuning** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0c78481e-0e93-4369-932f-d2b21f1dea0c",
    "_uuid": "dec481c2407ad73187e7b678fbdb9812f6a636a8"
   },
   "outputs": [],
   "source": [
    "def evalClassModel(model, y_test, y_pred_class, plot=False):\n",
    "    #Classification accuracy: percentage of correct predictions\n",
    "    # calculate accuracy\n",
    "    print('Accuracy:', metrics.accuracy_score(y_test, y_pred_class))\n",
    "    \n",
    "    #Null accuracy: accuracy that could be achieved by always predicting the most frequent class\n",
    "    # examine the class distribution of the testing set (using a Pandas Series method)\n",
    "    print('Null accuracy:\\n', y_test.value_counts())\n",
    "    \n",
    "    # calculate the percentage of ones\n",
    "    print('Percentage of ones:', y_test.mean())\n",
    "    \n",
    "    # calculate the percentage of zeros\n",
    "    print('Percentage of zeros:',1 - y_test.mean())\n",
    "    \n",
    "    #Comparing the true and predicted response values\n",
    "    print('True:', y_test.values[0:25])\n",
    "    print('Pred:', y_pred_class[0:25])\n",
    "    \n",
    "    #Conclusion:\n",
    "    #Classification accuracy is the easiest classification metric to understand\n",
    "    #But, it does not tell you the underlying distribution of response values\n",
    "    #And, it does not tell you what \"types\" of errors your classifier is making\n",
    "    \n",
    "    #Confusion matrix\n",
    "    # save confusion matrix and slice into four pieces\n",
    "    confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "    #[row, column]\n",
    "    TP = confusion[1, 1]\n",
    "    TN = confusion[0, 0]\n",
    "    FP = confusion[0, 1]\n",
    "    FN = confusion[1, 0]\n",
    "    \n",
    "    # visualize Confusion Matrix\n",
    "    sns.heatmap(confusion,annot=True,fmt=\"d\") \n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "    \n",
    "    #Metrics computed from a confusion matrix\n",
    "    #Classification Accuracy: Overall, how often is the classifier correct?\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred_class)\n",
    "    print('Classification Accuracy:', accuracy)\n",
    "    \n",
    "    #Classification Error: Overall, how often is the classifier incorrect?\n",
    "    print('Classification Error:', 1 - metrics.accuracy_score(y_test, y_pred_class))\n",
    "    \n",
    "    #False Positive Rate: When the actual value is negative, how often is the prediction incorrect?\n",
    "    false_positive_rate = FP / float(TN + FP)\n",
    "    print('False Positive Rate:', false_positive_rate)\n",
    "    \n",
    "    #Precision: When a positive value is predicted, how often is the prediction correct?\n",
    "    print('Precision:', metrics.precision_score(y_test, y_pred_class))\n",
    "    \n",
    "    \n",
    "    # IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "    print('AUC Score:', metrics.roc_auc_score(y_test, y_pred_class))\n",
    "    \n",
    "    # calculate cross-validated AUC\n",
    "    print('Cross-validated AUC:', cross_val_score(model, X, y, cv=10, scoring='roc_auc').mean())\n",
    "    \n",
    "    ##########################################\n",
    "    #Adjusting the classification threshold\n",
    "    ##########################################\n",
    "    # print the first 10 predicted responses\n",
    "    # 1D array (vector) of binary values (0, 1)\n",
    "    print('First 10 predicted responses:\\n', model.predict(X_test)[0:10])\n",
    "\n",
    "    # print the first 10 predicted probabilities of class membership\n",
    "    print('First 10 predicted probabilities of class members:\\n', model.predict_proba(X_test)[0:10])\n",
    "\n",
    "    # print the first 10 predicted probabilities for class 1\n",
    "    model.predict_proba(X_test)[0:10, 1]\n",
    "    \n",
    "    # store the predicted probabilities for class 1\n",
    "    y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    if plot == True:\n",
    "        # histogram of predicted probabilities\n",
    "        # adjust the font size \n",
    "        plt.rcParams['font.size'] = 12\n",
    "        # 8 bins\n",
    "        plt.hist(y_pred_prob, bins=8)\n",
    "        \n",
    "        # x-axis limit from 0 to 1\n",
    "        plt.xlim(0,1)\n",
    "        plt.title('Histogram of predicted probabilities')\n",
    "        plt.xlabel('Predicted probability of treatment')\n",
    "        plt.ylabel('Frequency')\n",
    "    \n",
    "    \n",
    "    # predict treatment if the predicted probability is greater than 0.3\n",
    "    # it will return 1 for all values above 0.3 and 0 otherwise\n",
    "    # results are 2D so we slice out the first column\n",
    "    y_pred_prob = y_pred_prob.reshape(-1,1) \n",
    "    y_pred_class = binarize(y_pred_prob, 0.3)[0]\n",
    "    \n",
    "    # print the first 10 predicted probabilities\n",
    "    print('First 10 predicted probabilities:\\n', y_pred_prob[0:10])\n",
    "    \n",
    "    ##########################################\n",
    "    #ROC Curves and Area Under the Curve (AUC)\n",
    "    ##########################################\n",
    "    \n",
    "    #Question: Wouldn't it be nice if we could see how sensitivity and specificity are affected by various thresholds, without actually changing the threshold?\n",
    "    #Answer: Plot the ROC curve!\n",
    "    \n",
    "    \n",
    "    #AUC is the percentage of the ROC plot that is underneath the curve\n",
    "    #Higher value = better classifier\n",
    "    roc_auc = metrics.roc_auc_score(y_test, y_pred_prob)\n",
    "    \n",
    "    \n",
    "\n",
    "    # IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "    # we pass y_test and y_pred_prob\n",
    "    # we do not use y_pred_class, because it will give incorrect results without generating an error\n",
    "    # roc_curve returns 3 objects fpr, tpr, thresholds\n",
    "    # fpr: false positive rate\n",
    "    # tpr: true positive rate\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob)\n",
    "    if plot == True:\n",
    "        plt.figure()\n",
    "        \n",
    "        plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.rcParams['font.size'] = 12\n",
    "        plt.title('ROC curve for treatment classifier')\n",
    "        plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "        plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    \n",
    "    # define a function that accepts a threshold and prints sensitivity and specificity\n",
    "    def evaluate_threshold(threshold):\n",
    "        #Sensitivity: When the actual value is positive, how often is the prediction correct?\n",
    "        #Specificity: When the actual value is negative, how often is the prediction correct?print('Sensitivity for ' + str(threshold) + ' :', tpr[thresholds > threshold][-1])\n",
    "        print('Specificity for ' + str(threshold) + ' :', 1 - fpr[thresholds > threshold][-1])\n",
    "\n",
    "    # One way of setting threshold\n",
    "    predict_mine = np.where(y_pred_prob > 0.50, 1, 0)\n",
    "    confusion = metrics.confusion_matrix(y_test, predict_mine)\n",
    "    print(confusion)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3e4552da-c5cc-45af-81ca-05a090922bb0",
    "_uuid": "4e5d57cfad5eee9dd3a34ed9da5fdccce8dc7c3a"
   },
   "source": [
    "### **Tuning with cross validation score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ff07e090-5af7-4a06-b553-c86a7a75cd64",
    "_uuid": "8ac94690bafb3277fec2d35bd196c317a33c9555"
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Tuning with cross validation score\n",
    "##########################################\n",
    "def tuningCV(knn):\n",
    "    \n",
    "    # search for an optimal value of K for KNN\n",
    "    k_range = list(range(1, 31))\n",
    "    k_scores = []\n",
    "    for k in k_range:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "        k_scores.append(scores.mean())\n",
    "    print(k_scores)\n",
    "    # plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)\n",
    "    plt.plot(k_range, k_scores)\n",
    "    plt.xlabel('Value of K for KNN')\n",
    "    plt.ylabel('Cross-Validated Accuracy')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2e05b3654a69f79cce46c2f5f007933de7dd91dc"
   },
   "source": [
    "<a id='Evaluating_models'></a>\n",
    "## **8. Evaluating models**<br><br>\n",
    "<a id='Logistic_regression'></a>\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8613beea-11e3-426b-91f6-39df3626eaf9",
    "_uuid": "89f5e2c8ec51637568ac22982649205ca1c340e2"
   },
   "outputs": [],
   "source": [
    "def logisticRegression():\n",
    "    # train a logistic regression model on the training set\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, y_train)\n",
    "    \n",
    "    # make class predictions for the testing set\n",
    "    y_pred_class = logreg.predict(X_test)\n",
    "    \n",
    "    print('########### Logistic Regression ###############')\n",
    "    \n",
    "    accuracy_score = evalClassModel(logreg, y_test, y_pred_class, True)\n",
    "    \n",
    "    #Data for final graph\n",
    "    methodDict['Log. Regres.'] = accuracy_score * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "de99d1dd-eb98-478c-9ed0-3cb518eac4b2",
    "_uuid": "1f71d045fa89ece846fe9e44559f057293e8bdf7"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2c090f3c-ecc9-433d-84a9-0d8f56cfd75d",
    "_uuid": "dd4c840a2b9a7ed7ad737730c4f780d11d603699"
   },
   "outputs": [],
   "source": [
    "logisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "406048fd-2312-4975-bd64-3db6cfe85aa5",
    "_uuid": "5c0bc7e355c38fa87b250b6a56e002611c0ede1d"
   },
   "source": [
    "<a id='Random_Forests'></a>\n",
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b5d831e8-3bcc-4e78-82bd-309a9a898954",
    "_uuid": "5419fdc8736774794575f2bd85a0f5341ad9d48d"
   },
   "outputs": [],
   "source": [
    "def randomForest():\n",
    "    # Calculating the best parameters\n",
    "    forest = RandomForestClassifier()\n",
    "\n",
    "    featuresSize = feature_cols.__len__()\n",
    "    param_dist = [{\"max_depth\": [3, 8],\n",
    "                   \"n_estimators\": [3, 10, 30],\n",
    "              \"max_features\": [1, 2, 8],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}]\n",
    "    \n",
    "    grid = GridSearchCV(forest, param_dist, cv=5, scoring=\"accuracy\")\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    # make class predictions for the testing set\n",
    "    y_pred_class = grid.best_estimator_.predict(X_test)\n",
    "    \n",
    "    print('########### Random Forests ###############')\n",
    "    \n",
    "    accuracy_score = evalClassModel(grid.best_estimator_, y_test, y_pred_class, True)\n",
    "\n",
    "    #Data for final graph\n",
    "    methodDict['R. Forest'] = accuracy_score * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d2b956e0-e921-4433-8cf1-3c4db0e26c12",
    "_uuid": "1c522cc7c4e6ba720b10620eb49f48274b24d79d"
   },
   "outputs": [],
   "source": [
    "randomForest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boosting():\n",
    "    # Building and fitting \n",
    "    clf = DecisionTreeClassifier()\n",
    "    boost = AdaBoostClassifier(base_estimator=clf)\n",
    "    \n",
    "    grid_params = [{\n",
    "        \"base_estimator__criterion\": [\"gini\", \"entropy\"],\n",
    "        \"base_estimator__max_depth\": [1, 2, 5],\n",
    "        \"n_estimators\": [50, 100, 500]\n",
    "    }]\n",
    "        \n",
    "    grid = GridSearchCV(boost, grid_params, cv=5, scoring=\"accuracy\")\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    boost = grid.best_estimator_\n",
    "    # make class predictions for the testing set\n",
    "    y_pred_class = boost.predict(X_test)\n",
    "    \n",
    "    print('########### Boosting ###############')\n",
    "    \n",
    "    accuracy_score = evalClassModel(boost, y_test, y_pred_class, True)\n",
    "\n",
    "    #Data for final graph\n",
    "    methodDict['Boosting'] = accuracy_score * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "05e05c13-6e1f-4900-b147-844cf49cdb41",
    "_uuid": "97b824045c3668ad8eab81bdfe35d07ab0d18c76"
   },
   "source": [
    "<a id='Creating_predictions_on_test_set'></a>\n",
    "## **11. Creating predictions on test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cd416a0e-a234-45c1-a502-e46d7b381dcd",
    "_uuid": "ddf3291a57a8ed1ebd10c81779abc44ff9f5ce72"
   },
   "outputs": [],
   "source": [
    "# Generate predictions with the best method\n",
    "clf = DecisionTreeClassifier()\n",
    "boost = AdaBoostClassifier(base_estimator=clf)\n",
    "\n",
    "grid_params = [{\n",
    "    \"base_estimator__criterion\": [\"gini\", \"entropy\"],\n",
    "    \"base_estimator__max_depth\": [1, 2, 5],\n",
    "    \"n_estimators\": [50, 100, 500]\n",
    "}]\n",
    "\n",
    "grid = GridSearchCV(boost, grid_params, cv=5, scoring=\"accuracy\")\n",
    "grid.fit(X_train, y_train)\n",
    "model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test)\n",
    "dfTestPredictions = model.predict(X_test)\n",
    "\n",
    "# Write predictions to csv file\n",
    "# We don't have any significative field so we save the index\n",
    "results = pd.DataFrame({'Index': X_test.index, 'Treatment': dfTestPredictions})\n",
    "# Save to file\n",
    "# This file will be visible after publishing in the output section\n",
    "results.to_csv('results.csv', index=False)\n",
    "results.head()\n",
    "\n",
    "joblib.dump(model, 'ada_bost_clf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.predict([[15,1,1,0,0,1,4,4]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_encoder = joblib.load(\"encoders/label_Gender.sav\")\n",
    "self_employee_encoder = joblib.load(\"encoders/label_self_employed.sav\")\n",
    "family_encoder = joblib.load(\"encoders/label_family_history.sav\")\n",
    "no_employees_encoder = joblib.load(\"encoders/label_no_employees.sav\")\n",
    "remote_work_encoder = joblib.load(\"encoders/label_remote_work.sav\")\n",
    "tech_company_encoder = joblib.load(\"encoders/label_tech_company.sav\")\n",
    "work_interfere_encoder = joblib.load(\"encoders/label_work_interfere.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = [\n",
    "    32,\n",
    "    gender_encoder.transform([\"trans\"]),\n",
    "    self_employee_encoder.transform([\"Yes\"]),\n",
    "    family_encoder.transform([\"No\"]),\n",
    "    no_employees_encoder.transform([\"6-25\"]),\n",
    "    remote_work_encoder.transform([\"Yes\"]),\n",
    "    tech_company_encoder.transform([\"No\"]),\n",
    "    work_interfere_encoder.transform([\"Rarely\"]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba([to_predict])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
